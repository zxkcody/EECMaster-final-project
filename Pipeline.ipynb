{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Pipeline for Micropaleontological Slide Image Analysis - PART I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow import keras\n",
    "import zipfile\n",
    "\n",
    "import mahotas as mt\n",
    "\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.utils import img_to_array\n",
    "from keras import optimizers, layers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import skimage\n",
    "from skimage.filters import threshold_multiotsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### function used for plotting segmented image after SAM\n",
    "###\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "    polygons = []\n",
    "    color = []\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        img = np.ones((m.shape[0], m.shape[1], 3))\n",
    "        color_mask = np.random.random((1, 3)).tolist()[0]\n",
    "        for i in range(3):\n",
    "            img[:,:,i] = color_mask[i]\n",
    "        ax.imshow(np.dstack((img, m*0.35)))\n",
    "\n",
    "### \n",
    "### function used to delete all png files in a certain directory\n",
    "###\n",
    "def delete_png_files(directory):\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.png'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted file: {file_path}\")\n",
    "            count += 1\n",
    "    print(f\"Total files deleted: {count}\")\n",
    "\n",
    "###\n",
    "### function used to save png images into a zip file\n",
    "###\n",
    "def save_png_as_zip(folder_path, zip_filename):\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zip:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith('.png'):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                zip.write(image_path, filename)\n",
    "\n",
    "###\n",
    "### function used to plot randomly sampled images from each cluster\n",
    "###\n",
    "def plot_random_samples(df, image_dir, num_samples=3):\n",
    "    # Initialize an empty dataframe to store the randomly sampled rows\n",
    "    sampled_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over unique cluster labels\n",
    "    for cluster_label in df['ClusterLabel'].unique():\n",
    "        # Filter the dataframe to include only rows with the current cluster label\n",
    "        cluster_df = df[df['ClusterLabel'] == cluster_label]\n",
    "\n",
    "        # Randomly sample rows from the current cluster\n",
    "        random_sample = cluster_df.sample(n=num_samples, random_state=42)  # Adjust the number of samples as needed\n",
    "\n",
    "        # Append the sampled rows to the new dataframe\n",
    "        sampled_df = pd.concat([sampled_df, random_sample])\n",
    "\n",
    "    # Group the dataframe by 'ClusterLabel'\n",
    "    grouped_df = sampled_df.groupby('ClusterLabel')\n",
    "\n",
    "    # Iterate over the groups and plot the images\n",
    "    for cluster_label, group in grouped_df:\n",
    "        # Create a subplot grid for the images in the current cluster\n",
    "        num_images = len(group)\n",
    "        num_cols = 5\n",
    "        num_rows = (num_images - 1) // num_cols + 1\n",
    "        fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, num_rows*2))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        # Iterate over the images in the current cluster and plot them\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            filename = row['filename']\n",
    "            i_value = row['i']\n",
    "            image_path = os.path.join(image_dir, f'ROI_{i_value}_{filename}.png')\n",
    "            img = plt.imread(image_path)\n",
    "\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'Cluster: {cluster_label}')\n",
    "\n",
    "        # Remove any empty subplots\n",
    "        for j in range(num_images, num_rows*num_cols):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "        # Adjust the spacing between subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Show the plot for the current cluster\n",
    "        plt.show()\n",
    "\n",
    "###\n",
    "### function used to plot all the images in one specific cluster\n",
    "###\n",
    "def plot_cluster_images(df, image_dir, cluster_label):\n",
    "    # Filter the dataframe to include only rows with the specified cluster label\n",
    "    cluster_df = df[df['ClusterLabel'] == cluster_label]\n",
    "\n",
    "    # Get the number of images in the cluster\n",
    "    num_images = len(cluster_df)\n",
    "\n",
    "    # Create a subplot grid for the images in the cluster\n",
    "    num_cols = 5\n",
    "    num_rows = (num_images - 1) // num_cols + 1\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, num_rows*2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Iterate over the images in the cluster and plot them\n",
    "    for i, (_, row) in enumerate(cluster_df.iterrows()):\n",
    "        filename = row['filename']\n",
    "        i_value = row['i']\n",
    "        image_path = os.path.join(image_dir, f'ROI_{i_value}_{filename}.png')\n",
    "        img = plt.imread(image_path)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Cluster: {cluster_label}')\n",
    "\n",
    "    # Remove any empty subplots\n",
    "    for j in range(num_images, num_rows*num_cols):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    # Adjust the spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot for the specified cluster\n",
    "    plt.show()\n",
    "\n",
    "###\n",
    "### function used to save all the images that are not in specified clusters\n",
    "###\n",
    "def save_non_cluster_images(df, image_dir, excluded_cluster_labels, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for cluster_label in df['ClusterLabel'].unique():\n",
    "        # Skip the cluster if it is in the excluded_cluster_labels\n",
    "        if cluster_label in excluded_cluster_labels:\n",
    "            continue\n",
    "\n",
    "        # Filter the dataframe to include only rows with the specified cluster label\n",
    "        cluster_df = df[df['ClusterLabel'] == cluster_label]\n",
    "\n",
    "        # Iterate over the images in the cluster and save them to the output directory\n",
    "        for _, row in cluster_df.iterrows():\n",
    "            filename = row['filename']\n",
    "            i_value = row['i']\n",
    "            image_path = os.path.join(image_dir, f'ROI_{i_value}_{filename}.png')\n",
    "            output_path = os.path.join(output_dir, f'ROI_{i_value}_{filename}.png')\n",
    "            shutil.copyfile(image_path, output_path)\n",
    "\n",
    "        print(f\"Saved {len(cluster_df)} images from Cluster {cluster_label} to {output_dir}.\")\n",
    "\n",
    "\n",
    "### \n",
    "### function used to save all the images in one specific cluster to a new folder\n",
    "###\n",
    "def save_cluster_images(df, image_dir, cluster_labels, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for cluster_label in cluster_labels:\n",
    "\n",
    "    # Filter the dataframe to include only rows with the specified cluster label\n",
    "        cluster_df = df[df['ClusterLabel'] == cluster_label]\n",
    "\n",
    "    # Iterate over the images in the cluster and save them to the output directory\n",
    "        for _, row in cluster_df.iterrows():\n",
    "            filename = row['filename']\n",
    "            i_value = row['i']\n",
    "            image_path = os.path.join(image_dir, f'ROI_{i_value}_{filename}.png')\n",
    "            output_path = os.path.join(output_dir, f'ROI_{i_value}_{filename}.png')\n",
    "            shutil.copyfile(image_path, output_path)\n",
    "\n",
    "        print(f\"Saved {len(cluster_df)} images from Cluster {cluster_label} to {output_dir}.\")\n",
    "\n",
    "###\n",
    "### function used to save all the images in one specific cluster to a new folder\n",
    "###\n",
    "def save_predicted_images(df, image_dir, predicted_labels, output_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for predicted_label in predicted_labels:\n",
    "\n",
    "    # Filter the dataframe to include only rows with the specified cluster label\n",
    "        predicted_df = df[df['predicted_label'] == predicted_label]\n",
    "\n",
    "    # Iterate over the images in the cluster and save them to the output directory\n",
    "        for _, row in predicted_df.iterrows():\n",
    "            filename = row['filename']\n",
    "            # i_value = row['i']\n",
    "            image_path = os.path.join(image_dir, f'{filename}')\n",
    "            output_path = os.path.join(output_dir, f'{filename}')\n",
    "            shutil.copyfile(image_path, output_path)\n",
    "\n",
    "        print(f\"Saved {len(predicted_df)} images from {predicted_label} to {output_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAM set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\" # cuda default\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_batch = 64, # default\n",
    "    points_per_side=32, # default\n",
    "    pred_iou_thresh=0.95, #default of 0.86\n",
    "    stability_score_thresh=0.92, # default\n",
    "    # crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Segmentation by SAM & Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = cv2.imread('/home/xzhu/517/New folder/SLT49-2ox 14 3 103 0.tif')\n",
    "sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.axis('off')\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_sample = mask_generator.generate(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(sample)\n",
    "show_anns(segmented_sample)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Otsu Thresholding for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input image.\n",
    "sample = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Applying multi-Otsu threshold for the default value, generating\n",
    "# three classes.\n",
    "thresholds = threshold_multiotsu(sample)\n",
    "\n",
    "# Using the threshold values, we generate the three regions.\n",
    "regions = np.digitize(sample, bins=thresholds)\n",
    "\n",
    "# Plotting the Multi Otsu result.\n",
    "plt.imshow(regions, cmap='jet')\n",
    "#plt.title('Multi-Otsu result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/xzhu/517/Toarcian AI project inc ox'\n",
    "delete_png_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/xzhu/517/New folder'\n",
    "#delete_png_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blank data frames to store the ouputs\n",
    "df1 = pd.DataFrame(columns = ['filename'])\n",
    "df2 = pd.DataFrame(columns = ['masks_length'])\n",
    "df3 = pd.DataFrame(columns = ['i'])\n",
    "df4 = pd.DataFrame(columns = ['stability_score'])\n",
    "# Calculating color based features - mean, std-dev of the RGB channels\n",
    "df5 = pd.DataFrame(columns = ['avg_blue']) #blue, green, red\n",
    "df6 = pd.DataFrame(columns = ['avg_green'])\n",
    "df7 = pd.DataFrame(columns = ['avg_red']) \n",
    "df8 = pd.DataFrame(columns = ['sd_blue'])\n",
    "df9 = pd.DataFrame(columns = ['sd_green'])\n",
    "df10 = pd.DataFrame(columns = ['sd_red'])\n",
    "# Shape based features calculated - Aspect ratio, rectangularity, circularity etc.\n",
    "df11 = pd.DataFrame(columns = ['size'])\n",
    "df12 = pd.DataFrame(columns = ['aspect_ratio'])\n",
    "df13 = pd.DataFrame(columns = ['rectangularity'])\n",
    "df14 = pd.DataFrame(columns = ['circularity'])\n",
    "df15 = pd.DataFrame(columns = ['convexity'])\n",
    "# Using Haralick moments - calculating texture based features such as contrast, correlation, entropy\n",
    "df16 = pd.DataFrame(columns = ['contrast'])\n",
    "df17 = pd.DataFrame(columns = ['correlation'])\n",
    "df18 = pd.DataFrame(columns = ['entropy'])\n",
    "df19 = pd.DataFrame(columns = ['inverse_difference_moments'])\n",
    "# for EF analysis\n",
    "df20 = pd.DataFrame(columns = ['perimeter'])\n",
    "#df20 = pd.DataFrame(columns = ['contour_coordinates']) \n",
    "\n",
    "\n",
    "# Create blank lists for the for loop\n",
    "filename_lst = []\n",
    "masks_lst = []\n",
    "i_lst = []\n",
    "stability_score_lst = []\n",
    "# Color\n",
    "avg_blue_lst = []\n",
    "avg_green_lst = []\n",
    "avg_red_lst = []\n",
    "sd_blue_lst = []\n",
    "sd_green_lst = []\n",
    "sd_red_lst = []\n",
    "# Shape\n",
    "size_lst = []\n",
    "aspect_ratio_lst = []\n",
    "rectangularity_lst = []\n",
    "circularity_lst = []\n",
    "convexity_lst = []\n",
    "# Texture\n",
    "contrast_lst = []\n",
    "correlation_lst = []\n",
    "entropy_lst =[]\n",
    "idm_lst = []\n",
    "# Contour\n",
    "perimeter_lst = []\n",
    "#coordinates_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original fossil image folder\n",
    "folder_path = '/home/xzhu/517/Toarcian AI project inc ox'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is a TIF image\n",
    "    if filename.endswith('.tif'):\n",
    "        # Read the image using OpenCV\n",
    "        image = cv2.imread(os.path.join(folder_path, filename))\n",
    "        # Generate masks for each image\n",
    "        masks = mask_generator.generate(image)\n",
    "\n",
    "        for i in range(len(masks)):\n",
    "            stability_score = masks[i]['stability_score']\n",
    "            # Create a mask image\n",
    "            mask_image = np.zeros_like(masks[i]['segmentation'], dtype = np.uint8)\n",
    "            mask_image[masks[i]['segmentation']] = 255\n",
    "            # Obtain segments in each image\n",
    "            segmentation = masks[i]['segmentation']\n",
    "            # Update mask image with segments\n",
    "            mask_image = image * segmentation[:,:,np.newaxis] # resize\n",
    "            # Combine original image with mask image\n",
    "            result = cv2.bitwise_and(image, mask_image)\n",
    "            result[mask_image==0] = 0 # black background\n",
    "        \n",
    "            ### for output images\n",
    "            # Create a mask image\n",
    "            out_image = np.zeros_like(masks[i]['segmentation'], dtype = np.uint8)\n",
    "            out_image[masks[i]['segmentation']] = 255\n",
    "            # Obtain segments in each image\n",
    "            segmentation = masks[i]['segmentation']\n",
    "            x, y, w, h = masks[i]['bbox']\n",
    "    \n",
    "            # Update mask image with segments\n",
    "            out_image = image * segmentation[:,:,np.newaxis] # resize\n",
    "            x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "            out_image = out_image[y:y+h, x:x+w]\n",
    "    \n",
    "            # Save each ROI as png file\n",
    "            cv2.imwrite(os.path.join(folder_path, 'ROI_{}_{}.png'.format(i, filename)), out_image)\n",
    "            ### end of output images\n",
    "\n",
    "            # Calculate the image contrast\n",
    "            img_grey = cv2.cvtColor(out_image, cv2.COLOR_BGR2GRAY)\n",
    "            contrast = img_grey.std()\n",
    "\n",
    "            textures = mt.features.haralick(img_grey)\n",
    "            ht_mean = textures.mean(axis=0)\n",
    "            correlation = ht_mean[2]\n",
    "            idm = ht_mean[4] #inverse difference moments\n",
    "            entropy = ht_mean[8]\n",
    "\n",
    "            # Calculate the average RGB\n",
    "            avg_color_per_row = np.average(result, axis = 0)\n",
    "            avg_color = np.average(avg_color_per_row, axis = 0) #blue, green, red\n",
    "\n",
    "            # Calculate the standard deviation RGB\n",
    "            sd_color_per_row = np.std(result, axis = 0)\n",
    "            sd_color = np.std(sd_color_per_row, axis = 0)\n",
    "\n",
    "            # Get the mask size\n",
    "            mask_size = masks[i]['area']\n",
    "            aspect_ratio = float(w)/h\n",
    "            rectangularity = mask_size / (w * h)\n",
    "            \n",
    "            # Append results to the blank list\n",
    "            filename_lst.append(filename)\n",
    "            masks_lst.append(len(masks))\n",
    "            i_lst.append(i)\n",
    "            stability_score_lst.append(stability_score)\n",
    "            avg_blue_lst.append(avg_color[0])\n",
    "            avg_green_lst.append(avg_color[1])\n",
    "            avg_red_lst.append(avg_color[2])\n",
    "            sd_blue_lst.append(sd_color[0])\n",
    "            sd_green_lst.append(sd_color[1])\n",
    "            sd_red_lst.append(sd_color[2])\n",
    "            size_lst.append(mask_size)\n",
    "            contrast_lst.append(contrast)\n",
    "            correlation_lst.append(correlation)\n",
    "            idm_lst.append(idm)\n",
    "            entropy_lst.append(entropy)\n",
    "\n",
    "            aspect_ratio_lst.append(aspect_ratio)\n",
    "            rectangularity_lst.append(rectangularity)\n",
    "            \n",
    "            # Create a binary mask image\n",
    "            co_image = np.zeros_like(masks[i]['segmentation'], dtype = np.uint8)\n",
    "            co_image[masks[i]['segmentation'] != 0 ] = 255\n",
    "            # Crop the image with bounding box\n",
    "            co_image = co_image[y:y+h, x:x+w]\n",
    "\n",
    "            # Find contours\n",
    "            contours,_= cv2.findContours(co_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            cnt = contours[0]\n",
    "            perimeter = cv2.arcLength(cnt,True)\n",
    "            circularity = ((perimeter)**2)/mask_size\n",
    "            circularity_lst.append(circularity)\n",
    "            perimeter_lst.append(perimeter)\n",
    "\n",
    "            # Convexity\n",
    "            # Calculate convex hull of the largest contour\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Create convex hull\n",
    "            hull = cv2.convexHull(largest_contour, returnPoints=True)\n",
    "            convex_area = cv2.contourArea(hull)\n",
    "            convexity = mask_size / convex_area\n",
    "\n",
    "            convexity_lst.append(convexity)\n",
    "\n",
    "            # create a blank list for each mask contour coordinates\n",
    "            #coordinates = []\n",
    "            #for contour in contours:\n",
    "            #    # Print the coordinates of each point in the contour\n",
    "            #    for point in contour:\n",
    "            #        x, y = point[0]\n",
    "            #        # save each (x,y) in the blank list\n",
    "            #        coordinates.append((x,y))\n",
    "                \n",
    "            #coordinates_lst.append(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['filename'] = filename_lst\n",
    "df2['masks_length'] = masks_lst\n",
    "df3['i'] = i_lst\n",
    "df4['stability_score'] = stability_score_lst\n",
    "df5['avg_blue'] = avg_blue_lst #blue, green, red\n",
    "df6['avg_green'] = avg_green_lst\n",
    "df7['avg_red'] = avg_red_lst\n",
    "df8['sd_blue'] = sd_blue_lst\n",
    "df9['sd_green'] = sd_green_lst\n",
    "df10['sd_red'] = sd_red_lst\n",
    "df11['size'] = size_lst\n",
    "df12['aspect_ratio'] = aspect_ratio_lst\n",
    "df13['rectangularity'] = rectangularity_lst\n",
    "df14['circularity'] = circularity_lst\n",
    "df15['convexity'] = convexity_lst\n",
    "df16['contrast'] = contrast_lst\n",
    "df17['correlation'] = correlation_lst\n",
    "df18['entropy'] = entropy_lst\n",
    "df19['inverse_difference_moments'] = idm_lst\n",
    "df20['perimeter'] = perimeter_lst\n",
    "#df20['contour_coordinates'] = coordinates_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, \n",
    "                    df10, df11, df12, df13, df14, df15, df16, df17, df18, df19, df20],axis = 1) # remove contour_coordinates\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output dataframe as csv file\n",
    "df_sum.to_csv(os.path.join(folder_path,r'RNS.csv'))\n",
    "#df_sum.to_csv(os.path.join(folder_path,r'SLT.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_png_as_zip(folder_path, 'RNS.zip')\n",
    "# save_png_as_zip(folder_path, 'SLT.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNS processed as the example below, SLT was processed in the same way\n",
    "\n",
    "csv_file = pd.read_csv('/home/xzhu/517/Toarcian AI project inc ox/RNS.csv')\n",
    "\n",
    "# csv_file = pd.read_csv('/home/xzhu/517/New folder/SLT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv_file[['i', 'filename', 'avg_blue', 'avg_green', 'avg_red', 'sd_blue', 'sd_green', 'sd_red', 'size', 'aspect_ratio','rectangularity',\n",
    "                  'circularity','contrast', 'correlation', 'entropy', 'perimeter']]\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_data = data[['avg_blue', 'avg_green', 'avg_red', 'sd_blue', 'sd_green', 'sd_red', 'size', 'aspect_ratio','rectangularity',\n",
    "                  'circularity','contrast', 'correlation', 'entropy','perimeter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the hc_data\n",
    "scaler = StandardScaler()\n",
    "scaled_hc_data = scaler.fit_transform(hc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means clustering (K = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3 # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "cluster_labels = kmeans.fit_predict(scaled_hc_data)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "data['ClusterLabel'] = cluster_labels # with filename\n",
    "\n",
    "# for further clustering analysis\n",
    "scaled_hc_data = pd.DataFrame(scaled_hc_data)\n",
    "scaled_hc_data['ClusterLabel'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_samples(data, folder_path, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_images(data, folder_path, 2) # plot to overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unqualified cluster\n",
    "print(\n",
    "    len(scaled_hc_data[scaled_hc_data['ClusterLabel'] == 2])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove masks in dataframe\n",
    "scaled_hc_data = scaled_hc_data[scaled_hc_data['ClusterLabel'] != 2]\n",
    "data =  data[data['ClusterLabel'] != 2]\n",
    "\n",
    "print(hc_data.shape)\n",
    "\n",
    "# remove clusterlabel column for further clustering\n",
    "scaled_hc_data = scaled_hc_data.drop(columns=['ClusterLabel'])\n",
    "print(scaled_hc_data.shape)\n",
    "\n",
    "data = data.drop(columns=['ClusterLabel'])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty array for weights\n",
    "weights = np.ones(14)\n",
    "\n",
    "weights[:6] = 0.1/6 # 0.1 for color features\n",
    "weights[6:10] = 0.6/4 # 0.5 for shape features\n",
    "weights[10:] = 0.3/4 # 0.4 for texture features\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_data = scaled_hc_data * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the linkage matrix\n",
    "hc = linkage(weighted_data, 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    hc,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = range(2, 101)\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    clusterer = KMeans(n_clusters=k, n_init=10)\n",
    "    preds = clusterer.fit_predict(scaled_hc_data)\n",
    "    centers = clusterer.cluster_centers_\n",
    "\n",
    "    score = silhouette_score(scaled_hc_data, preds)\n",
    "\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "    print(\"For n_clusters = {}, silhouette score is {}\".format(k, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Highest Silhouette Score: {max(silhouette_scores)}\")\n",
    "print(f\"Corresponding Number of Clusters: {silhouette_scores.index(max(silhouette_scores)) + 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = max(silhouette_scores)\n",
    "max_index = silhouette_scores.index(max_score) + 2\n",
    "\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.plot(k_values, silhouette_scores, 'bo-')\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for K-means Clustering')\n",
    "\n",
    "# Plot the highest silhouette score as a marker on the graph\n",
    "plt.plot(max_index, max_score, 'ro', markersize=10, label='Highest Silhouette Score')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrogram Truncation\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    hc,\n",
    "    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "    p=4,  # show only the last p merged clusters\n",
    "    show_leaf_counts=True,  # numbers in brackets are counts\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,  # to get a distribution impression in truncated branches\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100 # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "cluster_labels = kmeans.fit_predict(weighted_data)\n",
    "\n",
    "# Add cluster labels to the dataframe\n",
    "data['ClusterLabel'] = cluster_labels\n",
    "weighted_data['ClusterLabel'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendrogram Truncation\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    hc,\n",
    "    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "    p=100,  # show only the last p merged clusters\n",
    "    show_leaf_counts=True,  # numbers in brackets are counts\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,  # to get a distribution impression in truncated branches\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_samples(data, folder_path, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster_images(data, folder_path, 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(folder_path,r'clustered_RNS.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(os.path.join(folder_path,r'clustered_SLT.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Pipeline for Micropaleontological Slide Image Analysis - PART II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Microfossil Image Classification CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('/home/xzhu/517/Toarcian AI project inc ox/clustered_RNS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/home/xzhu/517/Toarcian AI project inc ox'\n",
    "\n",
    "fossil_dir = '/home/xzhu/517/cluster_label/fossil'\n",
    "noise_dir = '/home/xzhu/517/cluster_label/noise'\n",
    "\n",
    "test ='/home/xzhu/517/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty all the folders\n",
    "delete_png_files(fossil_dir)\n",
    "delete_png_files(noise_dir)\n",
    "delete_png_files(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to overview\n",
    "plot_cluster_images(csv, image_dir, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign images from clusters of interest to fossil/noise folder\n",
    "fossil_clusters = [29]\n",
    "save_cluster_images(csv, image_dir, fossil_clusters, fossil_dir)\n",
    "\n",
    "noise_clusters = [2, 3, 6, 7] # 0, 2, 3, 5, 6, 8\n",
    "save_cluster_images(csv, image_dir, noise_clusters, noise_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest images were treated as test image\n",
    "e = [29, 2, 3, 6, 7]\n",
    "save_non_cluster_images(csv, image_dir, e, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually check images in cluster 29 and remove the following 17 images\n",
    "filenames_to_remove = ['ROI_13_RNS1-1ox 37 0 101 3.tif.png',\n",
    "                       'ROI_3_RNS1-1 16 0 99 9.tif.png',\n",
    "                       'ROI_2_RNS 6-1ox 26 4 106 0.tif.png',\n",
    "                       'ROI_7_RNS 6-1ox 26 4 106 0.tif.png',\n",
    "                       'ROI_4_RNS1-1 23 6 100 8.tif.png',\n",
    "                       'ROI_9_RNS1-1 23 6 100 8.tif.png',\n",
    "                       'ROI_3_RNS 6-1ox 25 8 106 1.tif.png',\n",
    "                       'ROI_8_RNS1-1ox 46 5 101 9.tif.png',\n",
    "                       'ROI_8_RNS1-1 21 7 99 5.tif.png',\n",
    "                       'ROI_27_RNS1-1ox 42 2 102 3.tif.png',\n",
    "                       'ROI_2_RNS1-1ox 45 0 100 4.tif.png',\n",
    "                       'ROI_34_RNS1-1ox 47 1 102 0.tif.png',\n",
    "                       'ROI_7_RNS1-1ox 46 0 102 1.tif.png',\n",
    "                       'ROI_0_RNS 6-1ox 30 7 105 6.tif.png',\n",
    "                       'ROI_7_RNS 6-1ox 28 4 105 7.tif.png',\n",
    "                       'ROI_9_RNS 6-1ox 28 4 105 7.tif.png',\n",
    "                       'ROI_38_RNS 6-1ox 28 4 105 7.tif.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames_to_remove:\n",
    "    file_path = os.path.join(fossil_dir, filename)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Removed: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dataset\n",
    "image_folder = '/home/xzhu/517/cluster_label'\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  image_folder,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation split\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  image_folder,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "  print(image_batch.shape)\n",
    "  print(labels_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                  img_width,\n",
    "                                  3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes, name=\"outputs\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history1 = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "val_acc = []\n",
    "\n",
    "loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1 = history1.history['accuracy']\n",
    "val_acc1 = history1.history['val_accuracy']\n",
    "\n",
    "loss1 = history1.history['loss']\n",
    "val_loss1 = history1.history['val_loss']\n",
    "\n",
    "acc.extend(acc1)\n",
    "val_acc.extend(val_acc1)\n",
    "loss.extend(loss1)\n",
    "val_loss.extend(val_loss1)\n",
    "\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('/home/xzhu/517/Toarcian AI project inc ox/RNS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = pd.DataFrame(columns = ['filename'])\n",
    "df_label = pd.DataFrame(columns = ['predicted_label'])\n",
    "df_score = pd.DataFrame(columns = ['score'])\n",
    "\n",
    "filename_lst = []\n",
    "predicted_label_lst = []\n",
    "score_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test ='/home/xzhu/517/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 50 images one by one\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "# Get the list of image files in the test folder\n",
    "image_files = [filename for filename in os.listdir(test) if filename.endswith('.png')]\n",
    "\n",
    "# Iterate over the first 50 images in the test folder and plot them\n",
    "for filename in image_files[:50]:\n",
    "    image_path = os.path.join(test, filename)\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "        \n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "        \n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "    filename_lst.append(filename)\n",
    "    predicted_label_lst.append(np.argmax(score))\n",
    "    score_lst.append(100 * np.max(score))\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"{} most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "              .format(filename, class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename['filename'] = filename_lst\n",
    "df_label['predicted_label'] = predicted_label_lst # 1 = noise, 0 = fossil\n",
    "df_score['score'] = score_lst\n",
    "\n",
    "df_sum = pd.concat([csv, df_label, df_score],axis = 1)\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [0]\n",
    "n = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predicted_images(df_sum, image_dir, f, fossil_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predicted_images(df_sum, image_dir, n, noise_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move some identified noise image in fossil folder into noise folder\n",
    "import shutil\n",
    "\n",
    "noise_to_move = ['ROI_8_RNS1-1ox 32 5 99 7.tif.png',\n",
    "                 'ROI_29_RNS 6-1ox 25 1 106 2.tif.png',\n",
    "                 'ROI_29_RNS1-1 23 6 100 8.tif.png',\n",
    "                 'ROI_30_RNS1-1ox 45 5 100 0.tif.png',\n",
    "                 'ROI_33_RNS1-1ox 35 4 101 9.tif.png'\n",
    "                 ]\n",
    "\n",
    "for filename in noise_to_move:\n",
    "    source_path = os.path.join(fossil_dir, filename)\n",
    "    destination_path = os.path.join(noise_dir, filename)\n",
    "    shutil.move(source_path, destination_path)\n",
    "    print(f\"Moved: {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move some identified fossil image in noise folder into noise folder\n",
    "fossil_to_move = ['ROI_3_RNS 6-1ox 37 4 105 5.tif.png'\n",
    "                  ]\n",
    "\n",
    "for filename in fossil_to_move:\n",
    "    source_path = os.path.join(noise_dir, filename)\n",
    "    destination_path = os.path.join(fossil_dir, filename)\n",
    "    shutil.move(source_path, destination_path)\n",
    "    print(f\"Moved: {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '/home/xzhu/517/cluster_label'\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_folder,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation split\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  image_folder,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history2 = model.fit(  #trained_model\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = history2.history['accuracy']\n",
    "val_acc2 = history2.history['val_accuracy']\n",
    "\n",
    "loss2 = history2.history['loss']\n",
    "val_loss2 = history2.history['val_loss']\n",
    "\n",
    "# append to the previous model training results\n",
    "acc.extend(acc2)\n",
    "val_acc.extend(val_acc2)\n",
    "loss.extend(loss2)\n",
    "val_loss.extend(val_loss2)\n",
    "\n",
    "\n",
    "epochs_range = range(40)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = pd.DataFrame(columns = ['filename'])\n",
    "df_label = pd.DataFrame(columns = ['predicted_label'])\n",
    "df_score = pd.DataFrame(columns = ['score'])\n",
    "\n",
    "filename_lst = []\n",
    "predicted_label_lst = []\n",
    "score_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the second 50 images one by one\n",
    "plt.figure(figsize=(5, 6))\n",
    "\n",
    "# Get the list of image files in the test folder\n",
    "image_files = [filename for filename in os.listdir(test) if filename.endswith('.png')]\n",
    "\n",
    "# Iterate over the first 50 images in the test folder and plot them\n",
    "for filename in image_files[50:100]:\n",
    "    image_path = os.path.join(test, filename)\n",
    "    img = tf.keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "        \n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "        \n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "    filename_lst.append(filename)\n",
    "    predicted_label_lst.append(np.argmax(score))\n",
    "    score_lst.append(100 * np.max(score))\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"{} most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "              .format(filename, class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename['filename'] = filename_lst\n",
    "df_label['predicted_label'] = predicted_label_lst # 1 = noise, 0 = fossil\n",
    "df_score['score'] = score_lst\n",
    "\n",
    "df_sum = pd.concat([df_filename, df_label, df_score],axis = 1)\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predicted_images(df_sum, image_dir, f, fossil_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predicted_images(df_sum, image_dir, n, noise_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move some identified noise image in fossil folder into noise folder\n",
    "noise_to_move = ['ROI_2_RNS 6-1ox 32 0 105 8.tif.png',\n",
    "                'ROI_8_RNS1-1 25 3 101 6.tif.png',\n",
    "                'ROI_45_RNS 6-1ox 35 0 105 8.tif.png',\n",
    "                'ROI_40_RNS 6-1ox 30 0 105 7.tif.png',\n",
    "                'ROI_2_RNS1-1ox 32 5 99 7.tif.png',\n",
    "                'ROI_4_RNS 6-1ox 30 7 105 6.tif.png',\n",
    "                'ROI_22_RNS 6-1ox 30 0 105 7.tif.png',\n",
    "                'ROI_37_RNS 6-1ox 28 0 105 8.tif.png'\n",
    "                ]\n",
    "\n",
    "for filename in noise_to_move:\n",
    "    source_path = os.path.join(fossil_dir, filename)\n",
    "    destination_path = os.path.join(noise_dir, filename)\n",
    "    shutil.move(source_path, destination_path)\n",
    "    print(f\"Moved: {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_folder,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation split\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_folder,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history3 = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3 = history3.history['accuracy']\n",
    "val_acc3 = history3.history['val_accuracy']\n",
    "\n",
    "loss3 = history3.history['loss']\n",
    "val_loss3 = history3.history['val_loss']\n",
    "\n",
    "acc.extend(acc3)\n",
    "val_acc.extend(val_acc3)\n",
    "loss.extend(loss3)\n",
    "val_loss.extend(val_loss3)\n",
    "\n",
    "epochs_range = range(60)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = tf.keras.models.load_model('cnn_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Pipeline for Micropaleontological Slide Image Analysis - PART III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv with predicted labels\n",
    "inc = pd.read_csv('/home/xzhu/517/predicted_label_inc_84.csv')\n",
    "new = pd.read_csv('/home/xzhu/517/predicted_label_newfolder_84.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = noise, 0 = fossil\n",
    "inc_f = inc[inc['predicted_label'] == 0]\n",
    "new_f = new[new['predicted_label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_values_inc = inc_f['size']\n",
    "size_values_new = new_f['size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_size_inc = inc_f['size'].mean()\n",
    "mean_size_new = new_f['size'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_size_inc = size_values_inc.std()\n",
    "std_size_new = size_values_new.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for plotting\n",
    "dataframes = ['Toarcian pre-CIE', 'Toarcian post-CIE']\n",
    "\n",
    "# Increase the figure size to make the graph bigger\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a box plot to show the size values for each DataFrame\n",
    "boxplot = plt.boxplot([size_values_inc, size_values_new], labels=dataframes, vert=True, patch_artist=True, showfliers=False)\n",
    "\n",
    "# Customize the appearance of the box plot\n",
    "\n",
    "# Set box colors\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for patch, color in zip(boxplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Set the color of whiskers, caps, and medians\n",
    "for key in ['whiskers', 'caps', 'medians']:\n",
    "    for line in boxplot[key]:\n",
    "        line.set_color('black')\n",
    "\n",
    "# Set the linewidth of whiskers and caps\n",
    "for line in boxplot['whiskers'] + boxplot['caps']:\n",
    "    line.set_linewidth(1.5)\n",
    "\n",
    "# Set the linewidth and color of medians\n",
    "for line in boxplot['medians']:\n",
    "    line.set_linewidth(2)\n",
    "    line.set_color('red')\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Geological Era')\n",
    "plt.ylabel('Size (in cm2)')\n",
    "plt.title('Size Comparison between Microfossils from Different Eras')\n",
    "\n",
    "plt.tight_layout()  # Adjusts spacing to prevent clipping of labels\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "517",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
